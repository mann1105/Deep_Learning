{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iMmWhL2aOkGO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x) # Activation function\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XR8Wm8iEPT3h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Sigmoid\n",
        "nn.ReLU\n",
        "nn.LeakyReLU\n",
        "nn.Tanh;"
      ],
      "metadata": {
        "id": "QMLKNMj3QP67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for muticlass classification we use softmax function to handle multiple class output with cross-entropy loss function."
      ],
      "metadata": {
        "id": "QUXbJ6KqQUfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "# mini batch size\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syO3I-kOQrEt",
        "outputId": "b969825a-ce06-433d-f684-9b0d59b8fb82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 109677610.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 47006478.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 40028774.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6724507.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.h1 = nn.Linear(input_size, hidden_size)\n",
        "    self.h2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.h3 = nn.Linear(hidden_size, output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.h1(x)\n",
        "    x = self.sigmoid(x)\n",
        "    x = self.h2(x)\n",
        "    x = self.sigmoid(x)\n",
        "    x = self.h3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "09886l4ZQxqj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ykn7flIJeU-7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input dim = 28*28, hidden = 32, output = 10\n",
        "model = NeuralNet(784, 32, 10)\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1, 28*28).to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "\n",
        "    outputs = model(images)  # forwardI(images): get prediction\n",
        "    loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()  # automatic gradient calculation (autograd)\n",
        "    optimizer.step()  # update model parameter with requires_grad=True\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aZzdyr-bRTK",
        "outputId": "f916e266-2bda-49f6-b4ef-821053db56f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 2.3200\n",
            "Epoch [1/10], Step [200/469], Loss: 2.1254\n",
            "Epoch [1/10], Step [300/469], Loss: 1.5986\n",
            "Epoch [1/10], Step [400/469], Loss: 1.3250\n",
            "Epoch [2/10], Step [100/469], Loss: 0.8648\n",
            "Epoch [2/10], Step [200/469], Loss: 0.6574\n",
            "Epoch [2/10], Step [300/469], Loss: 0.7465\n",
            "Epoch [2/10], Step [400/469], Loss: 0.4570\n",
            "Epoch [3/10], Step [100/469], Loss: 0.4293\n",
            "Epoch [3/10], Step [200/469], Loss: 0.4575\n",
            "Epoch [3/10], Step [300/469], Loss: 0.3158\n",
            "Epoch [3/10], Step [400/469], Loss: 0.3487\n",
            "Epoch [4/10], Step [100/469], Loss: 0.4036\n",
            "Epoch [4/10], Step [200/469], Loss: 0.3436\n",
            "Epoch [4/10], Step [300/469], Loss: 0.3889\n",
            "Epoch [4/10], Step [400/469], Loss: 0.2489\n",
            "Epoch [5/10], Step [100/469], Loss: 0.2277\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2589\n",
            "Epoch [5/10], Step [300/469], Loss: 0.3160\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2727\n",
            "Epoch [6/10], Step [100/469], Loss: 0.4148\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2361\n",
            "Epoch [6/10], Step [300/469], Loss: 0.3846\n",
            "Epoch [6/10], Step [400/469], Loss: 0.3573\n",
            "Epoch [7/10], Step [100/469], Loss: 0.2039\n",
            "Epoch [7/10], Step [200/469], Loss: 0.2945\n",
            "Epoch [7/10], Step [300/469], Loss: 0.1984\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2032\n",
            "Epoch [8/10], Step [100/469], Loss: 0.2022\n",
            "Epoch [8/10], Step [200/469], Loss: 0.3522\n",
            "Epoch [8/10], Step [300/469], Loss: 0.3464\n",
            "Epoch [8/10], Step [400/469], Loss: 0.3795\n",
            "Epoch [9/10], Step [100/469], Loss: 0.2872\n",
            "Epoch [9/10], Step [200/469], Loss: 0.2511\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1730\n",
            "Epoch [9/10], Step [400/469], Loss: 0.1895\n",
            "Epoch [10/10], Step [100/469], Loss: 0.0901\n",
            "Epoch [10/10], Step [200/469], Loss: 0.1654\n",
            "Epoch [10/10], Step [300/469], Loss: 0.2623\n",
            "Epoch [10/10], Step [400/469], Loss: 0.2360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53JInvoIQJMh",
        "outputId": "6a498b22-daea-4cdc-d240-b01898ee8573"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 93.02 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJ4lCnOKRC1x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}