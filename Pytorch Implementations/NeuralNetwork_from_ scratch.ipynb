{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMXHuUQsxZvJ+cAhlLdrGfJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"id":"W3-p0OJxuX_Z","executionInfo":{"status":"ok","timestamp":1708829726235,"user_tz":-330,"elapsed":2,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn # to make the weight and bais tensors part of the neural network\n","import torch.nn.functional as af #gives us the activation functions\n","from torch import optim\n","from torch.optim import sgd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["class BasicNN(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Top\n","        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n","        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n","        self.w01 = nn.Parameter(torch.tensor(-40.8),requires_grad=False)\n","        # Bottom\n","        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n","        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n","        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n","\n","        self.final_bias = nn.Parameter(torch.tensor(-16.0), requires_grad=False)\n","\n","    def forward(self, input):\n","        # Top\n","        input_to_top_relu = input * self.w00 + self.b00\n","        top_relu_output = af.relu(input_to_top_relu)\n","        scaled_top_relu_output = top_relu_output * self.w01\n","\n","        # Bottom\n","        input_to_bottom_relu = input * self.w10 + self.b10\n","        bottom_relu_output = af.relu(input_to_bottom_relu)\n","        scaled_bottom_relu_output = bottom_relu_output * self.w11\n","\n","        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n","\n","        output = af.relu(input_to_final_relu)\n","\n","        return output"],"metadata":{"id":"2W8VqDAIvF2Q","executionInfo":{"status":"ok","timestamp":1708829338272,"user_tz":-330,"elapsed":2,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["input = torch.linspace(0,1,11)\n","input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1HZRwNC8ycJQ","executionInfo":{"status":"ok","timestamp":1708829339929,"user_tz":-330,"elapsed":3,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}},"outputId":"e649cf3d-963e-468c-d2d5-91437e82f13e"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n","        0.9000, 1.0000])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["model = BasicNN()\n","output = model(input)"],"metadata":{"id":"koE9ZQZF7i1P","executionInfo":{"status":"ok","timestamp":1708829340852,"user_tz":-330,"elapsed":2,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zLT7AFX7oGM","executionInfo":{"status":"ok","timestamp":1708829343409,"user_tz":-330,"elapsed":1737,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}},"outputId":"7e7e9aec-5cba-4f98-81ab-2d53bb4cf3ff"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0100, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NYE5rSk575tM","executionInfo":{"status":"ok","timestamp":1708829348836,"user_tz":-330,"elapsed":4,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# NN with back propogation\n"],"metadata":{"id":"un5llWmB8o2S"}},{"cell_type":"code","source":["class BasicNN_train(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Top\n","        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n","        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n","        self.w01 = nn.Parameter(torch.tensor(-40.8),requires_grad=False)\n","        # Bottom\n","        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n","        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n","        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n","\n","        self.final_bias = nn.Parameter(torch.tensor(0.), requires_grad=True) ##only change where final bais is upadated\n","\n","    def train(self, inputs, labels, test_inputs, learning_rate=0.1, epochs=100):\n","\n","        optimizer = optim.SGD(self.parameters(), learning_rate)\n","        print(\"Final bias, before optimization: \" + str(self.final_bias.data) + \"\\n\")\n","\n","        # plot = PlotInteractive(inputs, [0] * len(inputs))\n","\n","        for epoch in range(epochs):\n","            total_loss = 0\n","            for i in range(len(inputs)):\n","                input_i = inputs[i]\n","                label_i = labels[i]\n","\n","                output_i = self(input_i)\n","\n","                # Calculate Square Residual b/w output and known value\n","                loss = (output_i - label_i)**2\n","\n","                loss.backward()\n","                total_loss += float(loss)\n","            if(total_loss < 0.0001):\n","                print(\"Num steps: \" + str(epoch))\n","                break\n","\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            print(\"Step: \" + str(epoch) + \" Final Bias: \" + str(self.final_bias.data) + \"\\n\")\n","        print(\"Final Bias, after optimization: \" + str(self.final_bias.data))\n","        # plot.fin(self.final_bias.data)\n","\n","    def forward(self, input):\n","        # Top\n","        input_to_top_relu = input * self.w00 + self.b00\n","        top_relu_output = af.relu(input_to_top_relu)\n","        scaled_top_relu_output = top_relu_output * self.w01\n","\n","        # Bottom\n","        input_to_bottom_relu = input * self.w10 + self.b10\n","        bottom_relu_output = af.relu(input_to_bottom_relu)\n","        scaled_bottom_relu_output = bottom_relu_output * self.w11\n","\n","        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n","\n","        output = af.relu(input_to_final_relu)\n","\n","        return output"],"metadata":{"id":"yETJDMHz8sUd","executionInfo":{"status":"ok","timestamp":1708829730651,"user_tz":-330,"elapsed":420,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["input_doses = torch.linspace(0, 1, 21)\n","\n","# Train\n","input = torch.tensor([0.,.5,1.])\n","labels = torch.tensor([0,1,0])\n","\n","model = BasicNN_train()\n","\n","model.train(input, labels, input_doses)\n","output_value = model(input_doses)\n","\n","print(output_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAM1-tfrA0Rw","executionInfo":{"status":"ok","timestamp":1708829733174,"user_tz":-330,"elapsed":2103,"user":{"displayName":"Man Patel","userId":"16023284731064446233"}},"outputId":"c5ca3f3b-40f5-46c0-eacf-a01949406397"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Final bias, before optimization: tensor(0.)\n","\n","Step: 0 Final Bias: tensor(-3.2020)\n","\n","Step: 1 Final Bias: tensor(-5.7636)\n","\n","Step: 2 Final Bias: tensor(-7.8129)\n","\n","Step: 3 Final Bias: tensor(-9.4523)\n","\n","Step: 4 Final Bias: tensor(-10.7638)\n","\n","Step: 5 Final Bias: tensor(-11.8131)\n","\n","Step: 6 Final Bias: tensor(-12.6525)\n","\n","Step: 7 Final Bias: tensor(-13.3240)\n","\n","Step: 8 Final Bias: tensor(-13.8612)\n","\n","Step: 9 Final Bias: tensor(-14.2909)\n","\n","Step: 10 Final Bias: tensor(-14.6348)\n","\n","Step: 11 Final Bias: tensor(-14.9098)\n","\n","Step: 12 Final Bias: tensor(-15.1298)\n","\n","Step: 13 Final Bias: tensor(-15.3059)\n","\n","Step: 14 Final Bias: tensor(-15.4467)\n","\n","Step: 15 Final Bias: tensor(-15.5594)\n","\n","Step: 16 Final Bias: tensor(-15.6495)\n","\n","Step: 17 Final Bias: tensor(-15.7216)\n","\n","Step: 18 Final Bias: tensor(-15.7793)\n","\n","Step: 19 Final Bias: tensor(-15.8254)\n","\n","Step: 20 Final Bias: tensor(-15.8623)\n","\n","Step: 21 Final Bias: tensor(-15.8919)\n","\n","Step: 22 Final Bias: tensor(-15.9155)\n","\n","Step: 23 Final Bias: tensor(-15.9344)\n","\n","Step: 24 Final Bias: tensor(-15.9495)\n","\n","Step: 25 Final Bias: tensor(-15.9616)\n","\n","Step: 26 Final Bias: tensor(-15.9713)\n","\n","Step: 27 Final Bias: tensor(-15.9790)\n","\n","Step: 28 Final Bias: tensor(-15.9852)\n","\n","Step: 29 Final Bias: tensor(-15.9902)\n","\n","Step: 30 Final Bias: tensor(-15.9941)\n","\n","Step: 31 Final Bias: tensor(-15.9973)\n","\n","Step: 32 Final Bias: tensor(-15.9999)\n","\n","Step: 33 Final Bias: tensor(-16.0019)\n","\n","Num steps: 34\n","Final Bias, after optimization: tensor(-16.0019)\n","tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 1.0081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","        0.0000, 0.0000, 0.0000], grad_fn=<ReluBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"93fvpE-IA2ev"},"execution_count":null,"outputs":[]}]}